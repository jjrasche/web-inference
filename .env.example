# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Or use local models
LLM_PROVIDER=openai  # options: openai, anthropic, local
LLM_MODEL=gpt-4-turbo-preview
LLM_ENDPOINT=http://localhost:11434  # For local models

# Browser Configuration
BROWSER=chromium  # options: chromium, firefox, webkit
HEADLESS=false    # Set to true for headless operation

# Storage
DATABASE_URL=sqlite:///data/web_inference.db

# Web Interface (optional)
FLASK_PORT=5000
FLASK_DEBUG=true

# Logging
LOG_LEVEL=INFO